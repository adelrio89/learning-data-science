{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delightful  is a positive word\n",
      "awesome  is a positive word\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "positive_counter = 0\n",
    "tweet = 'We have some delightful new food in the cafeteria. Awesome!!!'\n",
    "positive_words = ['awesome','good', 'nice', 'super', 'fun', 'delightful']\n",
    "negative_words=['awful','lame','horrible','bad']\n",
    "\n",
    "#Preprocessing\n",
    "from string import punctuation\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "tweet_processed = tweet.lower()\n",
    "\n",
    "for p in list(punctuation):\n",
    "    tweet_processed = tweet_processed.replace(p,'')\n",
    "\n",
    "words = tweet_processed.split()   \n",
    "\n",
    "for word in words:\n",
    "    if word in positive_words:\n",
    "        print word, ' is a positive word'\n",
    "        positive_counter = positive_counter + 1\n",
    "\n",
    "print positive_counter/len(words)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "files=['negative.txt','positive.txt','obama_tweets.txt']\n",
    "path='http://www.unc.edu/~ncaren/haphazard/'\n",
    "for file_name in files:\n",
    "    urllib.urlretrieve(path+file_name,file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = open('obama_tweets.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = tweets.split('\\n')\n",
    "len(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama has called the GOP budget social Darwinism. Nice try, but they believe in social creationism.\n",
      "In his teen years, Obama has been known to use marijuana and cocaine.\n",
      "IPA Congratulates President Barack Obama for Leadership Regarding JOBS Act: WASHINGTON, Apr 05, 2012 (BUSINESS W... http://t.co/8le3DC8E\n",
      "RT @Professor_Why: #WhatsRomneyHiding - his connection to supporters of Critical Race Theory.... Oh wait, that was Obama, not Romney...\n",
      "RT @wardollarshome: Obama has approved more targeted assassinations than any modern US prez; READ & RT: http://t.co/bfC4gbBW\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets_list[0:5]:\n",
    "    print tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT @Professor_Why: #WhatsRomneyHiding - his connection to supporters of Critical Race Theory.... Oh wait, that was Obama, not Romney...']\n"
     ]
    }
   ],
   "source": [
    "print tweets_list[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from __future__ import division\n",
    "import urllib\n",
    "import csv\n",
    "\n",
    "files=['negative.txt','positive.txt','obama_tweets.txt']\n",
    "path='http://www.unc.edu/~ncaren/haphazard/'\n",
    "for file_name in files:\n",
    "    urllib.urlretrieve(path+file_name,file_name)\n",
    "\n",
    "tweets = open('obama_tweets.txt').read()\n",
    "tweets_list = tweets.split('\\n')\n",
    "\n",
    "pos_sent = open('positive.txt').read()\n",
    "positive_words = pos_sent.split('\\n')\n",
    "\n",
    "neg_sent = open('negative.txt').read()\n",
    "negative_words = neg_sent.split('\\n')\n",
    "\n",
    "\n",
    "positive_counts = []\n",
    "negative_counts = []\n",
    "\n",
    "\n",
    "for tweet in tweets_list:\n",
    "    tweet_processed = tweet.lower()\n",
    "    pos_counts = 0\n",
    "    neg_counts = 0\n",
    "    for p in list(punctuation):\n",
    "        tweet_processed = tweet_processed.replace(p,'')\n",
    "    words = tweet_processed.split(' ')\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            pos_counts += 1\n",
    "        else:\n",
    "            neg_counts += 1\n",
    "    positive_counts.append(round(pos_counts/len(words),2))\n",
    "    negative_counts.append(round(neg_counts/len(words),2))\n",
    "\n",
    "    \n",
    "output = zip(tweets_list, positive_counts, negative_counts)\n",
    "writer = csv.writer(open('tweets_sentiment.csv','wb'))\n",
    "writer.writerows(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
